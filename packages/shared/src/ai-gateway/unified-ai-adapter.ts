// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ¤– Unified AI Adapter - Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ÙˆØ­Ø¯ Ø§Ù„ÙƒØ§Ù…Ù„
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import Anthropic from '@anthropic-ai/sdk';
import OpenAI from 'openai';
import { GoogleGenerativeAI, SchemaType } from '@google/generative-ai';
import { Ollama } from 'ollama';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ“‹ Types - Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…ÙˆØ­Ø¯Ø©
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export type AIProvider = 'claude' | 'openai' | 'deepseek' | 'gemini' | 'ollama' | 'auto';

export interface Message {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export interface UnifiedToolDefinition {
  name: string;
  description: string;
  parameters: Record<string, any>;
}

export interface ToolCall {
  id: string;
  name: string;
  arguments: Record<string, any>;
}

export interface UnifiedRequest {
  messages: Message[];
  tools?: UnifiedToolDefinition[];
  maxTokens?: number;
  temperature?: number;
}

export interface UnifiedResponse {
  text: string;
  toolCalls?: ToolCall[];
  needsToolResults?: boolean;
  provider: AIProvider;
  model: string;
  cost: number;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ”„ AI Provider Adapter - Ø§Ù„Ù…Ø­ÙˆÙ„ Ø§Ù„Ù…ÙˆØ­Ø¯
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AIProviderAdapter {
  private claudeClient?: Anthropic;
  private openaiClient?: OpenAI;
  private deepseekClient?: OpenAI;
  private geminiClient?: GoogleGenerativeAI;
  private ollamaClient?: Ollama;

  constructor(config: {
    claude?: string;
    openai?: string;
    deepseek?: string;
    gemini?: string;
    ollama?: boolean;
  }) {
    if (config.claude) {
      this.claudeClient = new Anthropic({ apiKey: config.claude });
    }
    if (config.openai) {
      this.openaiClient = new OpenAI({ apiKey: config.openai });
    }
    if (config.deepseek) {
      this.deepseekClient = new OpenAI({
        apiKey: config.deepseek,
        baseURL: 'https://api.deepseek.com/v1',
      });
    }
    if (config.gemini) {
      this.geminiClient = new GoogleGenerativeAI(config.gemini);
    }
    if (config.ollama) {
      this.ollamaClient = new Ollama({ host: 'http://localhost:11434' });
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸš€ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© - Ø¥Ø±Ø³Ø§Ù„ Ù…ÙˆØ­Ø¯
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  async send(
    provider: AIProvider,
    request: UnifiedRequest
  ): Promise<UnifiedResponse> {
    switch (provider) {
      case 'claude':
        if (!this.claudeClient) throw new Error('Claude not configured');
        return await this.sendToClaude(request);

      case 'openai':
        if (!this.openaiClient) throw new Error('OpenAI not configured');
        return await this.sendToOpenAI(request, 'openai');

      case 'deepseek':
        if (!this.deepseekClient) throw new Error('DeepSeek not configured');
        return await this.sendToOpenAI(request, 'deepseek');

      case 'gemini':
        if (!this.geminiClient) throw new Error('Gemini not configured');
        return await this.sendToGemini(request);

      case 'ollama':
        if (!this.ollamaClient) throw new Error('Ollama not configured');
        return await this.sendToOllama(request);

      default:
        throw new Error(`Unknown provider: ${provider}`);
    }
  }

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // ğŸ”µ Claude Adapter
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  private async sendToClaude(request: UnifiedRequest): Promise<UnifiedResponse> {
    // 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ system prompt
    const systemMessage = request.messages.find((m) => m.role === 'system');
    const userMessages = request.messages.filter((m) => m.role !== 'system');

    // 2. ØªØ­ÙˆÙŠÙ„ Tools Ù„ØµÙŠØºØ© Claude
    const claudeTools = request.tools?.map((tool) => ({
      name: tool.name,
      description: tool.description,
      input_schema: {
        type: 'object' as const,
        properties: tool.parameters,
        required: Object.keys(tool.parameters),
      },
    }));

    // 3. ØªØ­ÙˆÙŠÙ„ Messages
    const claudeMessages = userMessages.map((m) => ({
      role: m.role as 'user' | 'assistant',
      content: m.content,
    }));

    // 4. Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
    const response = await this.claudeClient!.messages.create({
      model: 'claude-3-5-haiku-20241022',
      max_tokens: request.maxTokens || 4096,
      temperature: request.temperature || 0.7,
      system: systemMessage?.content,
      messages: claudeMessages,
      tools: claudeTools,
    });

    // 5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯
    return this.normalizeClaudeResponse(response);
  }

  // ğŸ”„ ØªÙˆØ­ÙŠØ¯ Ø±Ø¯ Claude
  private normalizeClaudeResponse(response: any): UnifiedResponse {
    let text = '';
    const toolCalls: ToolCall[] = [];

    for (const block of response.content) {
      if (block.type === 'text') {
        text += block.text;
      } else if (block.type === 'tool_use') {
        toolCalls.push({
          id: block.id,
          name: block.name,
          arguments: block.input,
        });
      }
    }

    // Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠØ©
    const inputTokens = response.usage?.input_tokens || 0;
    const outputTokens = response.usage?.output_tokens || 0;
    const cost = (inputTokens * 3.0 + outputTokens * 15.0) / 1_000_000;

    return {
      text,
      toolCalls: toolCalls.length > 0 ? toolCalls : undefined,
      needsToolResults: toolCalls.length > 0,
      provider: 'claude',
      model: response.model,
      cost,
    };
  }

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // ğŸŸ¢ OpenAI / DeepSeek Adapter
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  private async sendToOpenAI(
    request: UnifiedRequest,
    type: 'openai' | 'deepseek'
  ): Promise<UnifiedResponse> {
    const client = type === 'openai' ? this.openaiClient! : this.deepseekClient!;

    // 1. ØªØ­ÙˆÙŠÙ„ Tools Ù„ØµÙŠØºØ© OpenAI
    const openaiTools = request.tools?.map((tool) => ({
      type: 'function' as const,
      function: {
        name: tool.name,
        description: tool.description,
        parameters: {
          type: 'object' as const,
          properties: tool.parameters,
          required: Object.keys(tool.parameters),
        },
      },
    }));

    // 2. ØªØ­ÙˆÙŠÙ„ Messages (System ÙÙŠ messages)
    const openaiMessages = request.messages.map((m) => ({
      role: m.role,
      content: m.content,
    }));

    // 3. Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
    const response = await client.chat.completions.create({
      model: type === 'openai' ? 'gpt-4-turbo' : 'deepseek-chat',
      max_tokens: request.maxTokens || 4096,
      temperature: request.temperature || 0.7,
      messages: openaiMessages as any,
      tools: openaiTools,
    });

    // 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯
    return this.normalizeOpenAIResponse(response, type);
  }

  // ğŸ”„ ØªÙˆØ­ÙŠØ¯ Ø±Ø¯ OpenAI
  private normalizeOpenAIResponse(response: any, type: 'openai' | 'deepseek'): UnifiedResponse {
    const message = response.choices[0]?.message;
    const text = message?.content || '';
    const toolCalls: ToolCall[] = [];

    if (message?.tool_calls) {
      for (const call of message.tool_calls) {
        toolCalls.push({
          id: call.id,
          name: call.function.name,
          arguments: JSON.parse(call.function.arguments),
        });
      }
    }

    // Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙƒÙ„ÙØ©
    const inputTokens = response.usage?.prompt_tokens || 0;
    const outputTokens = response.usage?.completion_tokens || 0;

    let cost = 0;
    if (type === 'openai') {
      cost = (inputTokens * 10.0 + outputTokens * 30.0) / 1_000_000; // GPT-4 Turbo
    } else {
      cost = (inputTokens * 0.14 + outputTokens * 0.28) / 1_000_000; // DeepSeek
    }

    return {
      text,
      toolCalls: toolCalls.length > 0 ? toolCalls : undefined,
      needsToolResults: toolCalls.length > 0,
      provider: type === 'openai' ? 'openai' : 'deepseek',
      model: response.model,
      cost,
    };
  }

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // ğŸ”´ Gemini Adapter
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  private async sendToGemini(request: UnifiedRequest): Promise<UnifiedResponse> {
    const model = this.geminiClient!.getGenerativeModel({
      model: 'gemini-2.0-flash-exp',
    });

    // 1. ØªØ­ÙˆÙŠÙ„ Tools Ù„ØµÙŠØºØ© Gemini
    const geminiTools = request.tools
      ? [
          {
            functionDeclarations: request.tools.map((tool) => ({
              name: tool.name,
              description: tool.description,
              parameters: {
                type: SchemaType.OBJECT,
                properties: tool.parameters,
                required: Object.keys(tool.parameters),
              },
            })),
          },
        ]
      : undefined;

    // 2. ØªØ­ÙˆÙŠÙ„ Messages Ù„ØµÙŠØºØ© Gemini
    const systemMessage = request.messages.find((m) => m.role === 'system');
    const userMessages = request.messages.filter((m) => m.role !== 'system');

    const contents = userMessages.map((m) => ({
      role: m.role === 'assistant' ? 'model' : 'user',
      parts: [{ text: m.content }],
    }));

    // 3. Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
    const result = await model.generateContent({
      contents,
      systemInstruction: systemMessage?.content,
      tools: geminiTools,
      generationConfig: {
        maxOutputTokens: request.maxTokens || 4096,
        temperature: request.temperature || 0.7,
      },
    });

    // 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯
    return this.normalizeGeminiResponse(result);
  }

  // ğŸ”„ ØªÙˆØ­ÙŠØ¯ Ø±Ø¯ Gemini
  private normalizeGeminiResponse(result: any): UnifiedResponse {
    const response = result.response;
    let text = '';
    const toolCalls: ToolCall[] = [];

    for (const candidate of response.candidates || []) {
      for (const part of candidate.content?.parts || []) {
        if (part.text) {
          text += part.text;
        } else if (part.functionCall) {
          toolCalls.push({
            id: `gemini_${Date.now()}_${Math.random()}`,
            name: part.functionCall.name,
            arguments: part.functionCall.args,
          });
        }
      }
    }

    // Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠØ©
    const inputTokens = response.usageMetadata?.promptTokenCount || 0;
    const outputTokens = response.usageMetadata?.candidatesTokenCount || 0;
    const cost = (inputTokens * 0.1 + outputTokens * 0.4) / 1_000_000; // Gemini 2.0 Flash

    return {
      text,
      toolCalls: toolCalls.length > 0 ? toolCalls : undefined,
      needsToolResults: toolCalls.length > 0,
      provider: 'gemini',
      model: 'gemini-2.0-flash-exp',
      cost,
    };
  }

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // ğŸ  Ollama Adapter (Ù…Ø­Ù„ÙŠ ÙˆÙ…Ø¬Ø§Ù†ÙŠ)
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  private async sendToOllama(request: UnifiedRequest): Promise<UnifiedResponse> {
    // Ø§Ø³ØªØ®Ø±Ø§Ø¬ system prompt
    const systemMessage = request.messages.find((m) => m.role === 'system');
    const userMessages = request.messages.filter((m) => m.role !== 'system');

    // ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
    const messages = userMessages.map((msg) => ({
      role: msg.role,
      content: msg.content,
    }));

    // Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ollama
    const response = await this.ollamaClient!.chat({
      model: 'llama3.2', // Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
      messages: systemMessage
        ? [{ role: 'system', content: systemMessage.content }, ...messages]
        : messages,
      stream: false,
    });

    return {
      text: response.message.content,
      toolCalls: undefined, // Ollama tools ØªØ­ØªØ§Ø¬ ØªÙƒØ§Ù…Ù„ Ø¥Ø¶Ø§ÙÙŠ
      needsToolResults: false,
      provider: 'ollama',
      model: 'llama3.2',
      cost: 0, // Ù…Ø¬Ø§Ù†ÙŠ!
    };
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ¯ Unified AI Adapter - Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ§Ù…Ù„
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export class UnifiedAIAdapterWithTools {
  private adapter: AIProviderAdapter;
  private defaultProvider: AIProvider = 'deepseek';

  constructor(config: {
    claude?: string;
    openai?: string;
    deepseek?: string;
    gemini?: string;
    ollama?: boolean;
    defaultProvider?: AIProvider;
  }) {
    this.adapter = new AIProviderAdapter(config);
    if (config.defaultProvider) {
      this.defaultProvider = config.defaultProvider;
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ’¬ Ù…Ø­Ø§Ø¯Ø«Ø© Ø¨Ø¯ÙˆÙ† Ø£Ø¯ÙˆØ§Øª (Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ Ø­Ø§Ù„ÙŠØ§Ù‹)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  async chat(messages: Message[], provider?: AIProvider): Promise<UnifiedResponse> {
    const selectedProvider = provider || this.defaultProvider;
    return await this.adapter.send(selectedProvider, { messages });
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ­ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¹ Ø´Ø®ØµÙŠØ© (Ù„Ù„Ù€ Agents)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  async processWithPersonality(
    personalityOrRole: string,
    prompt: string,
    tools?: any,
    provider?: AIProvider
  ): Promise<{ response: string }> {
    // ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø®ØµÙŠØ©
    let systemContent = '';

    // Ø¥Ø°Ø§ ÙƒØ§Ù†Øª role Ù…Ø¹Ø±ÙˆÙØ©ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø´Ø®ØµÙŠØ© Ù…Ø­Ø¯Ø¯Ø©
    const personalities: Record<string, string> = {
      'architect': 'Ø£Ù†Øª Ù…Ù‡Ù†Ø¯Ø³ Ù…Ø¹Ù…Ø§Ø±ÙŠ Ø®Ø¨ÙŠØ± ÙÙŠ ØªØµÙ…ÙŠÙ… Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©. ØªØµÙ…Ù… Ø¨Ù†ÙŠØ§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙˆØ³Ø¹ ÙˆØ³Ù‡Ù„Ø© Ø§Ù„ØµÙŠØ§Ù†Ø©.',
      'backend': 'Ø£Ù†Øª Ù…Ø·ÙˆØ± Backend Ù…Ø­ØªØ±Ù Ù…ØªØ®ØµØµ ÙÙŠ Ø¨Ù†Ø§Ø¡ APIs ÙˆÙ‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø®Ù„ÙÙŠØ©.',
      'frontend': 'Ø£Ù†Øª Ù…Ù‡Ù†Ø¯Ø³ Frontend Ø®Ø¨ÙŠØ± ÙÙŠ Ø¨Ù†Ø§Ø¡ ÙˆØ§Ø¬Ù‡Ø§Øª Ù…Ø³ØªØ®Ø¯Ù… ØªÙØ§Ø¹Ù„ÙŠØ© ÙˆØ¬Ù…ÙŠÙ„Ø©.',
      'security': 'Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø£Ù…Ø§Ù† Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø«ØºØ±Ø§Øª ÙˆØªØ£Ù…ÙŠÙ† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª.',
      'reviewer': 'Ø£Ù†Øª Ù…Ø±Ø§Ø¬Ø¹ ÙƒÙˆØ¯ Ù…Ø­ØªØ±Ù ØªØ­Ù„Ù„ Ø§Ù„ÙƒÙˆØ¯ ÙˆØªÙ‚Ø¯Ù… Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†.',
      'tester': 'Ø£Ù†Øª Ù…Ù‡Ù†Ø¯Ø³ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø®Ø¨ÙŠØ± ÙÙŠ ÙƒØªØ§Ø¨Ø© ÙˆØªÙ†ÙÙŠØ° Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø´Ø§Ù…Ù„Ø©.',
      'debugger': 'Ø£Ù†Øª Ù…ØµØ­Ø­ Ø£Ø®Ø·Ø§Ø¡ Ù…Ø­ØªØ±Ù ØªØ¬Ø¯ ÙˆØªØ­Ù„ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø¨Ø³Ø±Ø¹Ø©.',
      'devops': 'Ø£Ù†Øª Ù…Ù‡Ù†Ø¯Ø³ DevOps Ù…ØªØ®ØµØµ ÙÙŠ CI/CD ÙˆØ§Ù„Ù†Ø´Ø± ÙˆØ§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªØ­ØªÙŠØ©.',
      'seo': 'Ø£Ù†Øª Ù…ØªØ®ØµØµ SEO Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø¨Ø­Ø«.',
      'ui-ux': 'Ø£Ù†Øª Ù…ØµÙ…Ù… UI/UX Ù…Ø­ØªØ±Ù ØªØµÙ…Ù… ØªØ¬Ø§Ø±Ø¨ Ù…Ø³ØªØ®Ø¯Ù… Ø±Ø§Ø¦Ø¹Ø©.',
      'optimizer': 'Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ù…ØªØ®ØµØµ ÙÙŠ Ø¬Ø¹Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø£Ø³Ø±Ø¹ ÙˆØ£ÙƒØ«Ø± ÙƒÙØ§Ø¡Ø©.',
      'ml': 'Ø£Ù†Øª Ù…Ù‡Ù†Ø¯Ø³ ØªØ¹Ù„Ù… Ø¢Ù„ÙŠ Ø®Ø¨ÙŠØ± ÙÙŠ Ø¨Ù†Ø§Ø¡ Ù†Ù…Ø§Ø°Ø¬ ML ÙˆAI.',
      'fullstack': 'Ø£Ù†Øª Ù…Ø·ÙˆØ± Fullstack Ø´Ø§Ù…Ù„ ØªØ¬Ù…Ø¹ Ø¨ÙŠÙ† Frontend ÙˆBackend.',
      'intelligent-predictor': 'Ø£Ù†Øª Ù…Ø­Ù„Ù„ ØªÙ†Ø¨Ø¤ÙŠ Ø°ÙƒÙŠ ØªØªÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ ÙˆØªÙ‚ØªØ±Ø­ Ø­Ù„ÙˆÙ„ Ø§Ø³ØªØ¨Ø§Ù‚ÙŠØ©.',
      'computer-control': 'Ø£Ù†Øª Ù†Ø¸Ø§Ù… ØªØ­ÙƒÙ… Ø­Ø§Ø³ÙˆØ¨ÙŠ Ø°ÙƒÙŠ ÙŠÙ…ÙƒÙ†Ù‡ ØªÙ†ÙÙŠØ° Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù„ÙØ§Øª.',
      'arabic-learning': 'Ø£Ù†Øª Ù…Ø¹Ù„Ù… Ø¨Ø±Ù…Ø¬Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…ØªØ®ØµØµ ÙÙŠ ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©.',
      'arabic-quality': 'Ø£Ù†Øª Ù…Ø¯Ù‚Ù‚ Ø¬ÙˆØ¯Ø© Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ ÙˆØ§Ù„ØªÙˆØ«ÙŠÙ‚.',
    };

    systemContent = personalities[personalityOrRole] || personalityOrRole;

    const messages: Message[] = [
      { role: 'system', content: systemContent },
      { role: 'user', content: prompt }
    ];

    const response = await this.chat(messages, provider);
    return { response: response.text };
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ”§ Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ø¹ Ø£Ø¯ÙˆØ§Øª (Ø§Ù„Ø¬Ø¯ÙŠØ¯!)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  async chatWithTools(
    messages: Message[],
    tools: UnifiedToolDefinition[],
    provider?: AIProvider
  ): Promise<UnifiedResponse> {
    // Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø²ÙˆØ¯ - Ø¥Ø°Ø§ Ø·Ù„Ø¨ toolsØŒ Ø§Ø³ØªØ®Ø¯Ù… Ù…Ø²ÙˆØ¯ ÙŠØ¯Ø¹Ù…Ù‡Ø§
    let selectedProvider = provider || this.selectProviderForTools();

    return await this.adapter.send(selectedProvider, {
      messages,
      tools,
    });
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ”„ Ù…Ø¹Ø§Ù„Ø¬Ø© Loop ÙƒØ§Ù…Ù„ Ù…Ø¹ Tools
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  async executeWithTools(
    messages: Message[],
    tools: UnifiedToolDefinition[],
    toolExecutor: (name: string, args: any) => Promise<string>,
    maxIterations: number = 10,
    provider?: AIProvider
  ): Promise<{ text: string; iterations: number; totalCost: number }> {
    const conversationHistory = [...messages];
    let iterations = 0;
    let totalCost = 0;

    while (iterations < maxIterations) {
      iterations++;

      // 1. Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
      const response = await this.chatWithTools(conversationHistory, tools, provider);
      totalCost += response.cost;

      // 2. Ø¥Ø°Ø§ Ù„Ø§ ØªÙˆØ¬Ø¯ tool callsØŒ Ø§Ù†ØªÙ‡ÙŠÙ†Ø§
      if (!response.needsToolResults) {
        return {
          text: response.text,
          iterations,
          totalCost,
        };
      }

      // 3. ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ø¯ÙˆØ§Øª
      const toolResults: string[] = [];
      for (const toolCall of response.toolCalls!) {
        console.log(`ğŸ”§ ØªÙ†ÙÙŠØ°: ${toolCall.name}(${JSON.stringify(toolCall.arguments)})`);
        const result = await toolExecutor(toolCall.name, toolCall.arguments);
        toolResults.push(result);
      }

      // 4. Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
      conversationHistory.push({
        role: 'assistant',
        content: response.text || `Ø§Ø³ØªØ®Ø¯Ù…Øª Ø§Ù„Ø£Ø¯ÙˆØ§Øª: ${response.toolCalls!.map((t) => t.name).join(', ')}`,
      });

      conversationHistory.push({
        role: 'user',
        content: `Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£Ø¯ÙˆØ§Øª:\n${toolResults.join('\n\n')}`,
      });
    }

    return {
      text: 'ÙˆØµÙ„Øª Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù…Ù† Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª',
      iterations,
      totalCost,
    };
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ¯ Ø§Ø®ØªÙŠØ§Ø± Ù…Ø²ÙˆØ¯ ÙŠØ¯Ø¹Ù… Tools
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  private selectProviderForTools(): AIProvider {
    // Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©:
    // 1. Gemini (Ø£Ø³Ø±Ø¹ ÙˆØ£Ø±Ø®Øµ ÙˆÙŠØ¯Ø¹Ù… tools)
    // 2. Claude (Ø£ÙØ¶Ù„ Ø¬ÙˆØ¯Ø© ÙˆÙŠØ¯Ø¹Ù… tools)
    // 3. OpenAI (ÙŠØ¯Ø¹Ù… tools Ù„ÙƒÙ† ØºØ§Ù„ÙŠ)
    // âš ï¸ DeepSeek Ù‚Ø¯ Ù„Ø§ ÙŠØ¯Ø¹Ù… tools - Ù†ØªØ¬Ù†Ø¨Ù‡

    // ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø²ÙˆØ¯ÙŠÙ† Ø§Ù„Ù…ØªØ§Ø­ÙŠÙ†
    return 'gemini'; // Ø§ÙØªØ±Ø§Ø¶ÙŠ
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ“ Ù…Ø«Ø§Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export async function example() {
  const adapter = new UnifiedAIAdapterWithTools({
    claude: process.env.ANTHROPIC_API_KEY,
    openai: process.env.OPENAI_API_KEY,
    deepseek: process.env.DEEPSEEK_API_KEY,
    gemini: process.env.GEMINI_API_KEY,
  });

  // ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£Ø¯ÙˆØ§Øª
  const tools: UnifiedToolDefinition[] = [
    {
      name: 'read_file',
      description: 'Ù‚Ø±Ø§Ø¡Ø© Ù…Ø­ØªÙˆÙ‰ Ù…Ù„Ù',
      parameters: {
        path: { type: 'string', description: 'Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù' },
      },
    },
    {
      name: 'write_file',
      description: 'ÙƒØªØ§Ø¨Ø© Ù…Ø­ØªÙˆÙ‰ Ù„Ù…Ù„Ù',
      parameters: {
        path: { type: 'string', description: 'Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù' },
        content: { type: 'string', description: 'Ø§Ù„Ù…Ø­ØªÙˆÙ‰' },
      },
    },
  ];

  // ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ø¯ÙˆØ§Øª
  const toolExecutor = async (name: string, args: any): Promise<string> => {
    if (name === 'read_file') {
      // Ù‚Ø±Ø§Ø¡Ø© ÙØ¹Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ù†Ø¸Ø§Ù…
      return `Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù: ${args.path}`;
    }
    if (name === 'write_file') {
      // ÙƒØªØ§Ø¨Ø© ÙØ¹Ù„ÙŠØ© Ù„Ù„Ù†Ø¸Ø§Ù…
      return `ØªÙ… Ø§Ù„ÙƒØªØ§Ø¨Ø© Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰: ${args.path}`;
    }
    return 'Ø£Ø¯Ø§Ø© ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©';
  };

  // Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹ Gemini (Ø£Ø³Ø±Ø¹ ÙˆØ£Ø±Ø®Øµ)
  const result = await adapter.executeWithTools(
    [
      { role: 'system', content: 'Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¨Ø±Ù…Ø¬Ø© Ø°ÙƒÙŠ' },
      { role: 'user', content: 'Ø§Ù‚Ø±Ø£ Ù…Ù„Ù package.json ÙˆØ£Ø¶Ù dependency Ø¬Ø¯ÙŠØ¯' },
    ],
    tools,
    toolExecutor,
    10,
    'gemini' // Ø£Ùˆ 'claude' Ù„Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ø£Ø¹Ù„Ù‰
  );

  console.log('Ø§Ù„Ù†ØªÙŠØ¬Ø©:', result.text);
  console.log('Ø¹Ø¯Ø¯ Ø§Ù„Ø¯ÙˆØ±Ø§Øª:', result.iterations);
  console.log('Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: $', result.totalCost.toFixed(4));
}
